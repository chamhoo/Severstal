{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('..'))\n",
    "\n",
    "from fiat.arch.image_seg import unet, resunet_arch\n",
    "# from fiat.components.arch import \n",
    "from fiat.os import count\n",
    "from fiat.data import TFR\n",
    "from fiat.train import train\n",
    "from fiat.losses import focal_tversky_loss, lossfromname\n",
    "from fiat.optimizer import optfromname\n",
    "from tools.data import feature_dict, decode_img_seg, seg_train_gen\n",
    "from fiat.DataAugment import flip_up_down, flip_left_right\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = os.path.join('..', 'data', 'train.csv')\n",
    "train_path = os.path.join('..', 'data', 'train_images')\n",
    "tfr_path = os.path.join('..', 'tmp', 'TFRecords', 'train')\n",
    "ckpt_path = os.path.join('..', 'tmp', 'ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfr = TFR(path=tfr_path,\n",
    "          count=count(train_path),\n",
    "          feature_dict=feature_dict, \n",
    "          shards=30, \n",
    "          compression='GZIP',\n",
    "          c_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch = unet(num_layers=5, \n",
    "            feature_growth_rate=32,\n",
    "            n_class=4,\n",
    "            channels=3,\n",
    "            padding='SAME',\n",
    "            dropout_rate=0.,\n",
    "            active='sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "arch = resunet_arch(reslayer='seresnet',\n",
    "                    numlayers='18',\n",
    "                    numstages=4,\n",
    "                    channels=64,\n",
    "                    n_class=4,\n",
    "                    padding='SAME',\n",
    "                    rate=0.25,\n",
    "                    active='sigmoid')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "read = tfr.read(decode_raw=decode_img_seg,\n",
    "                split=10,\n",
    "                valid=9, \n",
    "                # augment=[flip_up_down(), flip_left_right()],\n",
    "                buffer_size=400,\n",
    "                num_parallel_reads=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chamhaolee/anaconda3/envs/severstal/lib/python3.7/site-packages/tensorflow/python/data/ops/dataset_ops.py:1419: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1, train loss: 0.9763, valid metric: 0:  56%|█████▋    | 200/354 [00:47<00:32,  4.69it/s]"
     ]
    }
   ],
   "source": [
    "info = train(arch, read, \n",
    "             loss=focal_tversky_loss(), metric='dice', optimizer='adam',\n",
    "             rate=1e-6, epoch=1, batch_size=32, early_stopping=1,\n",
    "             verbose=2, retrain=False, reshape=[64, 400], reshape_method=3, ckpt_path=ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': [-4294967296, 0.9771569177441178],\n",
       " 'valid': [-4294967296, 0.014239655357907968]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fm = 200\n",
    "to = 201\n",
    "\n",
    "rate = 1e-4\n",
    "batch_size = 32\n",
    "epoch = 1\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('data'):\n",
    "    data, traincount, validcount = read()\n",
    "\n",
    "    for key, val in data.items():\n",
    "        data[key] = val.batch(batch_size)\n",
    "    dataset = data['train'].concatenate(data['valid'])\n",
    "\n",
    "    dataset = dataset.repeat(epoch)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    img, label = iterator.get_next()\n",
    "    img = tf.image.resize(img, size=[64, 400], method=2)\n",
    "    \n",
    "    y_pred, y_map = arch(img)\n",
    "    shape = tf.shape(y_pred)\n",
    "    y_true = tf.image.resize(label, [shape[1], shape[2]])\n",
    "    loss = focal_tversky_loss()(y_true, y_pred)\n",
    "    opt = optfromname('adam', learning_rate=rate, loss=loss)\n",
    "    \n",
    "#saver = tf.train.Saver(max_to_keep=epoch)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(iterator.initializer)\n",
    "    #saver.restore(sess, os.path.join(ckpt_path, f'epoch_1', 'model.ckpt'))\n",
    "    \n",
    "    for i in range(to):\n",
    "        img_arr, y_pred_arr, y_map_arr, loss_arr = sess.run((img, y_pred, y_map, loss))\n",
    "        if i >= fm:\n",
    "            print(y_map_arr)\n",
    "            plt.figure(figsize=[20, 20])\n",
    "            plt.subplot(9, 1, 1)\n",
    "            plt.imshow(img_arr[0].astype('int'))\n",
    "            for j in range(4):\n",
    "                plt.subplot(9, 1, j+2)\n",
    "                plt.imshow(y_pred_arr[0,:,:,j])\n",
    "                plt.subplot(9, 1, j+6)\n",
    "                plt.imshow(y_map_arr[0,:,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fm = 1000\n",
    "to = 1001\n",
    "\n",
    "rate = 1e-8\n",
    "batch_size = 32\n",
    "epoch = 1001 * batch_size // 5000\n",
    "tf.reset_default_graph()\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.name_scope('data'):\n",
    "    data, traincount, validcount = read()\n",
    "\n",
    "    for key, val in data.items():\n",
    "        data[key] = val.batch(batch_size)\n",
    "    dataset = data['train'].concatenate(data['valid'])\n",
    "\n",
    "    dataset = dataset.repeat(epoch)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "    img, label = iterator.get_next()\n",
    "    img = tf.image.resize(img, size=[64, 400], method=2)\n",
    "    \n",
    "    y_pred, y_map = arch(img)\n",
    "    shape = tf.shape(y_pred)\n",
    "    y_true = tf.image.resize(label, [shape[1], shape[2]])\n",
    "    loss = focal_tversky_loss()(y_true, y_pred)   #\n",
    "    opt = optfromname('gd', learning_rate=rate, loss=loss)\n",
    "    \n",
    "#saver = tf.train.Saver(max_to_keep=epoch)\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(iterator.initializer)\n",
    "    #saver.restore(sess, os.path.join(ckpt_path, f'epoch_1', 'model.ckpt'))\n",
    "    \n",
    "    for i in range(to):\n",
    "        img_arr, y_pred_arr, y_map_arr, loss_arr, _ = sess.run((img, y_pred, y_map, loss, opt))\n",
    "        if i >= fm:\n",
    "            print(y_map_arr)\n",
    "            plt.figure(figsize=[20, 20])\n",
    "            plt.subplot(9, 1, 1)\n",
    "            plt.imshow(img_arr[0].astype('int'))\n",
    "            for j in range(4):\n",
    "                plt.subplot(9, 1, j+2)\n",
    "                plt.imshow(y_pred_arr[0,:,:,j])\n",
    "                plt.subplot(9, 1, j+6)\n",
    "                plt.imshow(y_map_arr[0,:,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "data, _, _ = read()\n",
    "dataset = data['train']\n",
    "dataset = dataset.batch(1)\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "img_t, label_t = iterator.get_next()\n",
    "img_t = tf.image.resize(img_t, size=[128, 800], method=2)\n",
    "y, y_map = arch(img_t)\n",
    "shape = tf.shape(y)\n",
    "#saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run((tf.global_variables_initializer(), tf.local_variables_initializer()))\n",
    "    sess.run(iterator.initializer)\n",
    "    #saver.restore(sess, os.path.join(ckpt_path, f'epoch_1', 'model.ckpt'))\n",
    "    \n",
    "    for i in range(5):\n",
    "        img, label, y_mp, y_p = sess.run((img_t, label_t, y_map, y))\n",
    "        plt.figure(figsize=[20, 20])\n",
    "        plt.subplot(9, 1, 1)\n",
    "        plt.imshow(img[0].astype('int'))\n",
    "        for j in range(4):\n",
    "            plt.subplot(9, 1, j+2)\n",
    "            plt.imshow(y_p[0,:,:,j])\n",
    "            plt.subplot(9, 1, j+6)\n",
    "            plt.imshow(label[0,:,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
